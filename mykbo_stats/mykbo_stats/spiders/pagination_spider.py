import scrapy
from scrapy import Request

class MykboSpider(scrapy.Spider):
    name = "gameid_pagination_spider"
    allowed_domains = ["mykbostats.com"]
    start_urls = ["https://mykbostats.com/schedule"]
    
    week_count = 0  # Initialize week count
    max_weeks = 5  # Set the maximum number of weeks to scrape
    
    def parse(self, response):
        # Check if driver (Selenium) is sent with the request.meta
        if response.meta['driver'] is not None:
            # Read the browsers user-agent to check that we havent been blocked
            driver = response.meta['driver']
            user_agent = driver.execute_script("return navigator.userAgent;")
            self.logger.info(f"[parse] User-Agent: {user_agent}")
            
            if response.meta['driver_response'] is not None:
                # Print the actual HTML source code of the HtmlResponse generated by Selenium
                driver_response = response.meta['driver_response']
                self.logger.info("[parse] === page source ===\n{}".format(driver_response.text))
            
            games = response.css('a.game-line')
            self.logger.info(f"[parse] Found {len(games)} games")
            items = []
            for game in games:
                game_id = game.attrib['id'].split('-')[-1]  # Extract the game ID (just the number after 'game-line-')
                item = {
                    'game_id': game_id
                }
                items.append(item)
            
            # Find the "Previous Week" button and extract href
            prev_week_href = response.css("a.ui.button[href*='week_of']::attr(href)").get()

            if prev_week_href:
                self.week_count +=1
                if self.week_count > self.max_weeks:
                    self.logger.info(f"[parse] Reached max weeks ({self.max_weeks}), stopping pagination.")
                    return
                next_url = response.urljoin(prev_week_href)
                self.logger.info(f"[parse] Following pagination to {next_url}")
                yield Request(url=next_url, callback=self.parse, meta=response.meta)

            
            # yield items
            for item in items:
                yield item