import scrapy
from scrapy import Request

class MykboSpider(scrapy.Spider):
    name = "playerstats_spider"
    allowed_domains = ["mykbostats.com"]
    start_urls = ["https://mykbostats.com/schedule/week_of/2025-04-15"]  #Specific date with most games not cancelled
    
    def parse(self, response):
        # Check if driver (Selenium) is sent with the request.meta
        if response.meta['driver'] is not None:
            # Read the browsers user-agent to check that we havent been blocked
            driver = response.meta['driver']
            user_agent = driver.execute_script("return navigator.userAgent;")
            self.logger.info(f"[parse] User-Agent: {user_agent}")
            
            if response.meta['driver_response'] is not None:
                # Print the actual HTML source code of the HtmlResponse generated by Selenium
                driver_response = response.meta['driver_response']
                #self.logger.info("[parse] === page source ===\n{}".format(driver_response.text))
            
            games = response.css("a.game-line::attr(href)").getall()
            self.logger.info(f"[parse] Found {len(games)} games")
            for game_href in games[:2]:  # Limit to first 2 games for testing
                url = response.urljoin(game_href)
                print(f"Game URL: {url}")
                yield Request(url, callback=self.parse_game, meta={'driver': response.meta['driver'], 'driver_response': response.meta['driver_response']})

    def parse_game(self, response):
        # Check if driver (Selenium) is sent with the request.meta
        if response.meta['driver'] is not None:
            # Read the browsers user-agent to check that we havent been blocked
            driver = response.meta['driver']
            user_agent = driver.execute_script("return navigator.userAgent;")
            self.logger.info(f"[parse_game] User-Agent: {user_agent}")
            
            if response.meta['driver_response'] is not None:
                # Print the actual HTML source code of the HtmlResponse generated by Selenium
                driver_response = response.meta['driver_response']
                #self.logger.info("[parse_game] === page source ===\n{}".format(driver_response.text))
            
            # Extracting player stats for home team
            rows = response.css('table.away tbody tr')
            for row in rows:
                name = row.css('a.player-link::text').get()
                data_id = row.css('a.player-link::attr(data-id)').get()
                pos = row.css('td:nth-child(2)::text').get()
                ba = row.css('td.avg::text').get()
                ab = row.css('td:nth-child(4)::text').get()
                r = row.css('td:nth-child(5)::text').get()
                h = row.css('td:nth-child(6)::text').get()
                hr = row.css('td:nth-child(7)::text').get()
                rbi = row.css('td:nth-child(8)::text').get()
                bb = row.css('td:nth-child(9)::text').get()
                so = row.css('td:nth-child(10)::text').get()
                hbp = row.css('td:nth-child(11)::text').get()

                yield {
                    "name": name,
                    "player_id": data_id,
                    "position": pos,
                    "BA": ba,
                    "AB": ab,
                    "R": r,
                    "H": h,
                    "HR": hr,
                    "RBI": rbi,
                    "BB": bb,
                    "SO": so,
                    "HBP": hbp,
                    "source_url": response.url,
                }
                    
                    